# -*- coding: utf-8 -*-
"""OpenTA - Datanalys.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FOP4KmNJN3dtsK1hIcfAGoB-4In5gi6E

"""
import csv
from collections import defaultdict
import matplotlib.pyplot as plt
import numpy as np


def normalize_data(data_tensor, train_data_size):
    train_data = data_tensor[:train_data_size]
    mean_matrix = np.zeros(
        (train_data.shape[1], train_data.shape[2]))  # A matrix containing mean values for each dataset
    std_matrix = np.zeros((train_data.shape[1], train_data.shape[2]))
    for i, val in enumerate(train_data[0, 0, :]):
        # Normalize results dimension
        mean_matrix[0][i] = train_data[:, 0, i].mean(axis=0)
        data_tensor[:, 0, i] -= mean_matrix[0][i]
        std_matrix[0][i] = train_data[:, 0, i].std()
        if std_matrix[0][i] != 0:
            data_tensor[:, 0, i] /= std_matrix[0][i]
        # Normalize tries dimension
        mean_matrix[1][i] = train_data[:, 1, i].mean(axis=0)
        data_tensor[:, 1, i] -= mean_matrix[1][i]
        std_matrix[1][i] = train_data[:, 1, i].std()
        if std_matrix[1][i] != 0:
            data_tensor[:, 1, i] /= std_matrix[1][i]
        # Normalize time dimension
        mean_matrix[2][i] = train_data[:, 2, i].mean(axis=0)
        data_tensor[:, 2, i] -= mean_matrix[2][i]
        std_matrix[2][i] = train_data[:, 2, i].std()
        if std_matrix[2][i] != 0:
            data_tensor[:, 2, i] /= std_matrix[2][i]
    return data_tensor


def normalize_results(results_data):  # As of now only converts to 0 or 1
    # Normalize results vector - simplify output space to 0 or 1 for passed or not passed
    for i, result in enumerate(results_data):
        if float(results_data[i]) >= 5:  # If more than 4 points, the user passed the exam
            results_data[i] = float(1)
        else:
            results_data[i] = float(0)
    return results_data


# Reads the OpenTA-data file to a dictionary
def parse_csv_by_field(filename, fieldnames):
    d = defaultdict(list)
    with open(filename, newline='') as csvfile:
        reader = csv.DictReader(csvfile, fieldnames)
        next(reader)  # remove header
        for row in reader:
            for field in fieldnames:
                d[field].append(row[field])
    return dict(d)


# Separate the data corresponding to each user
# Create a new dict for each user, containing a dict with each user's data (a dict of dicts)
# 'nest_key' is the key which will contain the key in the super dict. I.e. 'user_hash' for a
# dict of dicts for each user.
# 'data_dict' is the original dict which will be nested
def create_nested_dict(nest_key, data_dict):
    d = {}
    sub_dict = defaultdict(list)

    for key in data_dict:
        if key != nest_key:
            sub_dict[key] = data_dict[key]

    for item in data_dict[nest_key]:
        d[item] = defaultdict(list)

    iteration = 0
    for item in data_dict[nest_key]:
        for sub_key in sub_dict:
            d[item][sub_key].append(sub_dict[sub_key][iteration])
        iteration += 1
    return (d)


# ********************* METHODS FOR PARSING SUBTASKS ***************************#
def find_earliest_timstamp(subtask, exercise_dict):
    if subtask in exercise_dict:
        question_dict = exercise_dict[subtask]
        datestring = question_dict['date'][-1] + question_dict['time'][-1]  # Find first entry for the current subtask
        datestring = datestring.split('+')[0]
        datestring = datestring.split("'")[1]
        try:
            timestamp = datetime.strptime(datestring, '%Y-%m-%d %H:%M:%S.%f')  # Convert to datetime object
        except ValueError:
            # Some strings are of other format for some reason
            # print('Wrong format!')
            timestamp = datetime.strptime(datestring, '%Y-%m-%d %H:%M:%S')
            # print(timestamp)
    else:
        timestamp = datetime.strptime('2017-06-01 23:59:59.000',
                                      '%Y-%m-%d %H:%M:%S.%f')  # Default date is the day before the day of the exam
    return timestamp


def find_right_or_wrong(subtask, exercise_dict):
    if subtask in exercise_dict:
        answer = exercise_dict[subtask]['correct']
        # print(answer)
        if " 'True'" in answer:
            solved = 1
        else:
            solved = 0
        # print(solved)
    else:
        solved = 0  # Default to not solved
    return float(solved)


def find_nbr_of_tries(subtask, exercise_dict):
    if subtask in exercise_dict:
        answers = exercise_dict[subtask]['correct']
        # print(answers)
        answers.reverse()  # Start from the back
        tries = 0
        for answer in answers:
            tries += 1
            if answer == " 'True'":
                break
        # print(tries)
    else:
        tries = 0  # Defualt tries is zero
    return float(tries)


def main():
    # ************************** Import OpenTA-data *********************************
    fieldnames = ['user', 'exercise', 'question', 'correct', 'date', 'time']
    openta = parse_csv_by_field('/content/gdrive/My Drive/OpenTA-data/Modified by hand/anonymized-ffm521-2017.csv',
                                fieldnames)

    # Read openta-results data
    fieldnames = ['user', 'exam', 'bonus', 'project']
    openta_results = parse_csv_by_field('/content/gdrive/My Drive/OpenTA-data/Modified by hand/results_ffm521_2017.csv',
                                        fieldnames)

    """## Organize OpenTA data"""

    # ************************** Organize OpenTA-data *******************************
    # Group data by users
    user_data = create_nested_dict('user', openta)
    # Now for each user, group by excercise
    for key in user_data:
        user_data[key] = create_nested_dict('exercise', user_data[key])
        # Finally group for each sub question
        for sub_key in user_data[key]:
            user_data[key][sub_key] = create_nested_dict('question', user_data[key][sub_key])

    # Nest result data
    results_data = create_nested_dict('user', openta_results)

    # Iterate through both lists, and if someone hasn't completed the exam or haven't used openta, input a default value

    # If someone is in the results_data (written the exam) but not in user_data,
    # they have completed the exam but not used OpenTA. They have then completed no
    # no exercises (list of length 0, empty)
    print('Users who have not used OpenTA')
    nbr = 0;
    for user in results_data:
        if user not in user_data.keys():
            # user_data[user] = defaultdict(list)  # Create a sub
            user_data[user] = {};  # Empty dict, no exercises
            nbr += 1
            print('\t' + user)
    print('Total: ' + str(nbr))
    print('\n')
    # If someone is in the user_data (used OpenTA) but not in the results_data they
    # have used OpenTA but not written the exam.
    print('Users who did not write the exam:')
    nbr = 0;
    for user in user_data:
        if user not in results_data:
            results_data[user] = defaultdict(list)
            results_data[user]['exam'] = ['-10']  # Negative score on exam indicates not having it written
            print('\t' + user)
            nbr += 1
    print('Total: ' + str(nbr))

    # **Show nested data**
    #
    print(user_data.keys())
    user_id = '7045617b05666b9ebc248328bf7635b9'  # The first user in the list
    print('User id: ' + user_id)
    for key in user_data[user_id]:
        print('\t Excerciseid: ' + key)
        for sub_key in user_data[user_id][key]:
            print('\t \t Questionid: ' + sub_key)
            print('\t \t \t Tries: ', end='')
            print(user_data[user_id][key][sub_key])

    # print('\n')
    # for key in user_data["'7b0289603b5427e9e23df7a8efe712ff'"]:
    #  print('Excerciseid: ' + key)
    #  #print(user_data["'d58f5d327a3253e88f97fdff23022d4f'"][key].keys())
    #  print(user_data["'7b0289603b5427e9e23df7a8efe712ff'"][key])

    print(len(user_data.keys()))
    print(len(results_data.keys()))

    # for user in results_data:
    #  print(user_data[user])

    print(results_data['7045617b05666b9ebc248328bf7635b9'])

    """## Analyze OpenTA data: e.g. find and plot results vs. number of exercises done

    ### Note that the people who both haven't used OpenTA and written the exam aren't represented in this dataset.
    """

    # ************************** Analyze data ***************************************
    # Find number of excercises for each user:
    number_of_exercises = defaultdict(list)
    for user in user_data:
        number_of_exercises[user] = len(user_data[user])

    # Create a list of number of exercises for each user
    sorted_by_exercises = sorted(number_of_exercises.items(), key=lambda kv: kv[1])
    # print(sorted_by_exercises)

    # Plot the number of exercises tried on OpenTA vs. exam result:

    for user in user_data:
        plt.plot(number_of_exercises[user], float(results_data[user]['exam'][0]),
                 'ro')  # Nbr of exercises on x-axis, exam result in points on y axis
    plt.title('Points on exam vs. exercises started on OpenTA  (-10 = no exam)')
    plt.xlabel('Number of exercises started')
    plt.ylabel('Points on exam')
    plt.show()

    """## Prepare data for training"""

    # ********************* Prepate data for training *******************************

    # ********************************* SCRIPT *************************************#
    # Create a list of all exercises
    all_exercises = defaultdict(list)  # name, subtasks
    for user in user_data:
        for exercise in user_data[user]:
            for subtask in user_data[user][exercise]:
                if subtask not in all_exercises[exercise]:
                    all_exercises[exercise].append(subtask)  # Add all subtasks which atleast someone has done
    # print(all_exercises)
    print('Total number of unique exercises: ' + str(len(all_exercises.keys())))

    # Create a sorted list of exercises for a user, starting with the earliest
    # tried exercise.
    from datetime import datetime

    sorted_user_data = {}  # Not actually sorted at the moment, but could probably be sorted
    temp_user_data = user_data  # use temp instead of overwriting user data
    for user in user_data:
        # print('New user: ' + user)
        sorted_user_data[user] = [[], [],
                                  []]  # Exercise ID:questionID (add extra column if this is required), Right/wrong, number of tries, first tried
        for exercise in all_exercises:
            # print('New exercise: ' + exercise)
            # print(user_data[user].keys())
            if exercise not in user_data[user]:
                # print('Added exercise')
                temp_user_data[user][
                    exercise] = {}  # If user haven't tried exercise at all, create a new entry without any completed subtasks
            iter = 0
            for subtask in all_exercises[exercise]:
                # sorted_user_data[user][0].append(exercise + ':' + subtask)  # Fill in first column
                sorted_user_data[user][0].append(find_right_or_wrong(subtask, temp_user_data[user][exercise]))
                sorted_user_data[user][1].append(find_nbr_of_tries(subtask, temp_user_data[user][exercise]))
                sorted_user_data[user][2].append(find_earliest_timstamp(subtask, temp_user_data[user][
                    exercise]))  # Find earliest timestamp for this question
                iter += 1
                # print('Fields added: ' + str(iter))

    # print(sorted_user_data.keys())
    # userhash = '29bbe8263d4313adab27338f33ebd0c5'
    # print('Total number of users (including people who wrote the exam but did not use OpenTA): ' + str(len(sorted_user_data.keys())))
    # print('Number of unique subtasks: ' + str(len(sorted_user_data[user][0])))
    # print('Chosen user: ' +  userhash)
    # print('Each block corresponds to a row in the user matris')
    # print()
    # for i, val in enumerate(sorted_user_data[user][0]):
    #  print('\t' + '********************************************************************')
    #  print('\t' + 'ExerciseID:questionID: '+ str(sorted_user_data[userhash][0][i]))
    #  print('\t' + 'Right/wrong: ' + str(sorted_user_data[userhash][1][i]))
    #  print('\t' + 'Number of tries: ' + str(sorted_user_data[userhash][2][i]))
    #  print('\t' + 'Date first tried: ' + str(sorted_user_data[userhash][3][i]))
    #  print('\t' + '********************************************************************')
    #  print()

    # Convert time to an integer between the course start and course end (exam)
    # ********************************* TODO ***************************************#
    # Exam date
    exam_date = datetime.strptime('2017-06-01 23:59:59.000',
                                  '%Y-%m-%d %H:%M:%S.%f')  # TODO Fix automatic finding of date
    course_start = datetime.strptime('2017-03-19 23:59:59.000', '%Y-%m-%d %H:%M:%S.%f')
    # ******************************************************************************#
    # epoch = datetime.utcfromtimestamp(0)
    # print(epoch)

    for user in sorted_user_data:
        for i, val in enumerate(sorted_user_data[user][0]):
            sorted_user_data[user][2][i] = float(
                (sorted_user_data[user][2][i] - course_start).total_seconds())  # Seconds from course start
            # print(sorted_user_data[user][3][i])
    # print(sorted_user_data['30ce9f4fa65266f698a5c9db315b3420'][3])
    # ******************************* Normalize Matrix data ************************#
    # Convert the dict above to a matrix, with one dimension being the user dimension
    user_list = []  # A list of users; contains the numbering information in the matrices below
    user_data_matrix = []  # A list of matrices, where each input is a user
    results_data_matrix = []  # user, exam points for user

    for i, user in enumerate(sorted_user_data):
        # print('_________________New user___________________')
        user_list.append(user)
        user_data_matrix.append(sorted_user_data[user])
        results_data_matrix.append(results_data[user]['exam'][0])
        # print(user_list[i])
        # print(user_data_matrix[i])
        # print(results_data_matrix[i])
    # print(type(user_data_matrix[0][0][0]))
    # print(type(user_data_matrix[0][1][0]))
    # print(type(user_data_matrix[0][2][0]))
    # print(type(user_data_matrix[0][3][0]))

    # Convert to numpy arrays
    float_data = np.asarray(user_data_matrix, dtype=np.float32)
    float_results = np.asarray(results_data_matrix, dtype=np.float32)
    user_list_numpy = np.asarray(user_list)

    # Remove exercise column - TODO
    # exercise_list_numpy = float_data[:, 0, :][0]  # Save the exercises in an ordered list corresponding to the float_data rows

    print('Matrix dimensions: ' + str(
        float_data.shape))  # Should be users, parameters ( +1 for the exercise dimension), nbr of exercises
    # print(results_data_numpy.shape)
    # print(user_list_numpy.shape)

    # print(float_data[:, 1, 0].shape)
    # print('here he comes')
    # print(np.mean(float_data[:, 1, 0]))
    # print(float_data[:,1,0].mean(axis=0))

    """# Training"""

    # ******************************Iteration 1 (Simon)**************************
    # Randomize users for separating data sets
    nbr_of_test = 0
    train_size = 100
    np.random.seed(1000)
    random_users = np.random.randint(0, float_data.shape[0] - nbr_of_test, size=float_data.shape[0] - nbr_of_test)

    shuffled_float_data = float_data[random_users]
    shuffled_float_results = float_results[random_users]

    # ************************** Normalization fix *********************************
    # Training and validation data have to be retaken from the now normalized data.
    norm_float_data = normalize_data(shuffled_float_data, train_size)
    norm_float_results = normalize_results(shuffled_float_results)

    x_train = norm_float_data[:train_size]
    # x_test = for future reference
    y_train = norm_float_results[:train_size]
    # y_test = for future reference
    x_val = norm_float_data[train_size:]
    y_val = norm_float_results[train_size:]


if __name__ == '__main__':
    main()
